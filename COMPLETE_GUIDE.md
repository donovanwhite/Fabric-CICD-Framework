# Microsoft Fabric CI/CD - COMPLETE GUIDE

## üìã OVERVIEW

This guide documents a practical solution for Microsoft Fabric CI/CD using the fabric-cicd library, based on testing and community feedback.

## ‚úÖ TEST RESULTS

- **‚úÖ 8/8 Fabric items deployed successfully**
- **‚úÖ Repository with subdirectory structure (Migration/, Warehouse/)**
- **‚úÖ Items: 6 Notebooks + 1 Lakehouse + 1 Warehouse**
- **‚úÖ Authentication: DefaultAzureCredential working effectively**
- **‚úÖ Deployment time: Under 2 minutes**
- **‚úÖ Folder structure preserved automatically**

## üîë RECOMMENDED APPROACH

### 1. Use Simple `publish_all_items()` Function
**‚úÖ RECOMMENDED:** Follow the basic fabric-cicd documentation pattern
```python
from fabric_cicd import FabricWorkspace, publish_all_items

workspace = FabricWorkspace(
    workspace_id="your-workspace-id",
    repository_directory="/path/to/repo",
    item_type_in_scope=["Notebook", "Lakehouse", "Warehouse"]
)

result = publish_all_items(workspace)
```

**‚ùå NOT RECOMMENDED:** Complex parameter.yml configurations, hybrid REST API approaches

### 2. Let fabric-cicd Handle Subdirectories Natively
**‚úÖ RECOMMENDED:** Repository structure with items in subdirectories
```
/<repository-root>
    /<Migration>/
        /nb_analysis.Notebook
        /data_lake.Lakehouse
    /<Warehouse>/
        /analytics_wh.Warehouse
```

**‚ùå NOT RECOMMENDED:** Flattening structures, manual folder creation via REST API

### 3. Specify Correct Item Types Based on Repository Analysis
**‚úÖ RECOMMENDED:** Auto-detect item types or specify based on actual content
```python
item_types = ["Notebook", "Lakehouse", "Warehouse"]  # Based on repository analysis
**‚ùå NOT RECOMMENDED:** Guessing item types, including types not in repository

### 4. Use DefaultAzureCredential
**‚úÖ RECOMMENDED:** Simple, reliable authentication
```bash
az login
# Then run your deployment script
```

**‚ùå NOT RECOMMENDED:** Complex authentication schemes, manual token management

## üìÅ REPOSITORY STRUCTURE REQUIREMENTS

### Supported Structure
```
/<repository-root>
    /<workspace-subfolder>/          # e.g., Migration/
        /<item-name>.<item-type>     # e.g., nb_capacity_migration_report.Notebook
        /<item-name>.<item-type>     # e.g., fabric_item_lakehouse.Lakehouse
    /<workspace-subfolder>/          # e.g., Warehouse/
        /<item-name>.<item-type>     # e.g., wh_sample_data.Warehouse
    /README.md                       # Optional files (ignored by fabric-cicd)
```

### Item Type Extensions
- `.Notebook` - Jupyter notebooks
- `.Lakehouse` - Data lakehouses
- `.Warehouse` - Data warehouses
- `.SemanticModel` - Semantic models/datasets
- `.Report` - Power BI reports
- `.DataPipeline` - Data pipelines
- `.Environment` - Spark environments
- `.Dataflow` - Dataflows

## üõ†Ô∏è STEP-BY-STEP IMPLEMENTATION

### Step 1: Environment Setup
```bash
# Create Python environment
python -m venv fabric-cicd
source fabric-cicd/bin/activate  # Linux/Mac
# OR
fabric-cicd\Scripts\activate  # Windows

# Install dependencies
pip install fabric-cicd GitPython azure-identity
```

### Step 2: Authentication
```bash
# Authenticate with Azure
az login

# Verify authentication
az account show
```

### Step 3: Repository Analysis
```bash
# Use our script to analyze your repository
python fabric_cicd_setup.py \
    --workspace-id "your-workspace-id" \
    --repo-url "your-repo-url" \
    --dry-run
```

### Step 4: Deployment
```bash
# Deploy using recommended approach
python fabric_cicd_setup.py \
    --workspace-id "your-workspace-id" \
    --repo-url "your-repo-url"
```

## üí° LESSONS LEARNED FROM TESTING

### What We Tested That Failed

1. **Complex parameter.yml Configurations**
   - Error: "Invalid parameter name 'find_key' found in the parameter file"
   - Solution: Use minimal or no parameter.yml file

2. **Flattening Repository Structures**
   - Problem: Lost folder organization in workspace
   - Solution: Let fabric-cicd handle subdirectories natively

3. **Hybrid REST API + fabric-cicd Approaches**
   - Problem: Unnecessary complexity, authentication issues
   - Solution: Use pure fabric-cicd library approach

4. **Manual Folder Creation via REST API**
   - Error: "Folder" is not a valid item type for Fabric API
   - Solution: Let fabric-cicd create folders automatically

### What Actually Works

1. **Simple publish_all_items() Function**
   - Reliable, follows documentation exactly
   - Handles all complexity internally

2. **Auto-Detection of Item Types**
   - Analyze repository to find actual item types
   - Specify only what exists in the repository

3. **DefaultAzureCredential Authentication**
   - Works seamlessly with Azure CLI
   - No complex token management needed

4. **Native Subdirectory Support**
   - fabric-cicd handles workspace subfolders perfectly
   - Preserves repository structure in workspace

## üîß TROUBLESHOOTING GUIDE

### Common Issues and Solutions

#### 1. "No module named 'git'"
```bash
pip install GitPython
```

#### 2. Authentication Errors
```bash
az login
az account show  # Verify authentication
```

#### 3. "No Fabric items found"
**Check:**
- Repository structure matches expected format
- Items have correct extensions (.Notebook, .Lakehouse, etc.)
- Items are in proper subdirectories

#### 4. Permission Errors
**Verify:**
- You have Admin or Member role in target workspace
- Workspace ID is correct (GUID format)
- DefaultAzureCredential has proper permissions

#### 5. Parameter Validation Errors
**Solution:** Use minimal configuration, avoid complex parameter.yml files

## üìä PERFORMANCE METRICS

Based on our testing with 8 Fabric items:
- **Repository Analysis:** ~10 seconds
- **Authentication:** ~5 seconds  
- **Item Deployment:** ~60-90 seconds
- **Total Time:** Under 2 minutes
- **Success Rate:** 100% (8/8 items deployed)

## üéØ BEST PRACTICES

### Do's ‚úÖ
- Use simple `publish_all_items()` function
- Let fabric-cicd handle subdirectories natively
- Auto-detect item types from repository
- Use DefaultAzureCredential for authentication
- Run with `--dry-run` first to validate
- Keep repository structure organized with subfolders

### Don'ts ‚ùå
- Don't use complex parameter.yml configurations
- Don't flatten repository structures
- Don't mix REST API calls with fabric-cicd
- Don't guess item types - analyze repository first
- Don't try to create folders manually via API

## üìã PARAMETERIZATION GUIDE

For cross-environment deployments, we've included `parameter_example.yml` with comprehensive real-world examples.

### üåü **When to Use Parameterization**
- **Multi-environment deployments** (DEV ‚Üí UAT ‚Üí PROD)
- **Cross-region migrations** with different connection strings
- **Dynamic item references** between Fabric artifacts
- **Environment-specific configurations** (different database servers, storage accounts, API endpoints)

### üìä **Parameter Example Features**

#### **üè¢ Complete Retail Analytics Example**
The example demonstrates a realistic retail analytics platform with:
- **Environments**: DEV, UAT, PROD configurations
- **19 Item Types**: All fabric-cicd v0.1.24 supported types
- **Real Values**: Actual connection patterns (sanitized for security)

#### **üîß Three Configuration Types**

1. **`find_replace`** - Simple string replacement
   ```yaml
   - find_value: "retail-source-dev.database.windows.net"
     replace_value:
       DEV: "retail-source-dev.database.windows.net"
       UAT: "retail-source-uat.database.windows.net"
       PROD: "retail-source-prod.database.windows.net"
     item_type: "DataPipeline"
   ```

2. **`key_value_replace`** - JSONPath-based updates
   ```yaml
   - find_key: "$.model.dataSources[0].connectionDetails.address.server"
     replace_value:
       DEV: "retailwarehouse-dev.datawarehouse.fabric.microsoft.com"
       PROD: "retailwarehouse-prod.datawarehouse.fabric.microsoft.com"
     item_type: "SemanticModel"
   ```

3. **`spark_pool`** - Environment-specific Spark pools
   ```yaml
   - instance_pool_id: "large-pool-12345678-abcd-ef12-3456-789012345678"
     replace_value:
       DEV: {type: "Workspace", name: "DevPool_Small"}
       PROD: {type: "Workspace", name: "ProdPool_Large"}
     item_type: "Environment"
   ```

#### **üîí Dynamic References**
- **Workspace Variables**: `$workspace.id` - Automatically resolved
- **Item References**: `$items.Lakehouse.DataLake.id` - Cross-artifact dependencies
- **Security Patterns**: Key Vault integration, managed identity examples

#### **üåç Real-World Connection Patterns**
- **SQL Server**: `server-env.database.windows.net`
- **Storage Accounts**: `accountnameenv.dfs.core.windows.net`
- **Event Hubs**: `namespace-env.servicebus.windows.net`
- **APIs**: `api-env.company.com`

### üìù **Usage with Parameterization**
```bash
# Deploy with environment-specific parameters
python fabric_cicd_setup.py \
    --workspace-id "your-workspace-id" \
    --repo-url "your-repo-url" \
    --environment PROD

# The script automatically:
# 1. Detects parameter.yml in repository
# 2. Applies environment-specific replacements  
# 3. Deploys items with updated configurations
```

### ‚ö†Ô∏è **Important Notes**
- **Start Simple**: Use basic deployment first, add parameterization when needed
- **Security**: Never commit real secrets - use Key Vault references
- **Testing**: Always test with DEV environment before PROD
- **Validation**: Parameter validation errors indicate overly complex configurations

## üöÄ AZURE DEVOPS INTEGRATION

### Pipeline Configuration (Tested)
```yaml
trigger:
- main

pool:
  vmImage: 'ubuntu-latest'

variables:
  FABRIC_WORKSPACE_ID: 'your-workspace-id'
  PYTHON_VERSION: '3.11'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: $(PYTHON_VERSION)

- script: |
    pip install fabric-cicd GitPython azure-identity
  displayName: 'Install Dependencies'

- script: |
    python fabric_cicd_setup.py \
      --workspace-id "$(FABRIC_WORKSPACE_ID)" \
      --repo-url "$(Build.Repository.Uri)" \
      --branch "$(Build.SourceBranchName)"
  displayName: 'Deploy Fabric Items'
  env:
    AZURE_CLIENT_ID: $(AZURE_CLIENT_ID)
    AZURE_CLIENT_SECRET: $(AZURE_CLIENT_SECRET)
    AZURE_TENANT_ID: $(AZURE_TENANT_ID)
```

### Service Principal Setup
```bash
# Create service principal for pipeline
az ad sp create-for-rbac --name "fabric-cicd-pipeline" --role contributor

# Add to Azure DevOps as service connection
# Use the output values for AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_TENANT_ID
```

## üìã VALIDATION CHECKLIST

Before deployment, ensure:
- [ ] Repository structure matches expected format
- [ ] Items have correct extensions (.Notebook, .Lakehouse, etc.)
- [ ] Authentication is working (`az account show`)
- [ ] Workspace ID is correct and accessible
- [ ] Python environment has required packages
- [ ] Dry run completes successfully

## üéâ SUCCESS VERIFICATION

After deployment:
1. **Check Fabric workspace** - All items should be visible
2. **Verify folder structure** - Subdirectories should be preserved
3. **Test item functionality** - Open notebooks, query warehouses
4. **Validate connections** - Ensure data sources are accessible

## üìû SUPPORT AND NEXT STEPS

### If You Encounter Issues:
1. Run with `--dry-run` first
2. Check repository structure against examples
3. Verify authentication with `az account show`
4. Review error messages for specific issues

### For Advanced Scenarios:
- Multi-environment deployments (dev/test/prod)
- Cross-region migrations
- Custom item type handling
- Integration with other CI/CD tools

---

*This guide represents tested solutions with the fabric-cicd library. Follow these patterns for reliable Fabric CI/CD deployments.*
